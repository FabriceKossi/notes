= Devoxx France 2023
:imagesdir: ./images
:toc:

== Mercredi

=== Une Architecture GitOps from scratch : Gitlab, Ansible, Terraform, Kubernetes et AWS

.Speakers : Loïc Ortola et Aurélien Moreau (@Takima)

Infra complete en GitOps:
C'est quoi une infra complete? archi 3 tier

Stack appli:front en angular, Api spring boot
Database pgsql 
Kubernetes 
Prometheus pour la surveillance 
Terraform Ansible. 
(photo) 

Point de départ :compte AWS, un domaine acheté chez Gandi

Crash course

==== infra as code

1. Provisioning d'infra (hardware) . Il me faut des serveurs pour pouvoir host mon infra (serveurs, réseau etc... Provisioning d'knfra->cloud provider permettende monter des serveur plus facilement 
2.Configuration management installatiln du socle technique qui va nous permettre de faire tourner mon appli. management
3orchestration d'application. Faire tourner les appli, gérer le cycle de vie de l'app, gestio'
L'infra as code c'est faire tout ça ensemble 

IaC c'est faire sous forme de code 

==== Gitops

L'iaC comme d'écrire précédemment te représente ton truc à un temps t
Mais faut le versionner.
Gitops c'est d'avoir une source de vérité Git, dans lequel je mets mon code d'infra que je vais pouvoir synchroniser à un instant t par rapport à ce qui est déployé

Cas autoscale du cluster. Si on demande plus de ressources que dispo à note cluster. 

==== De docker à Kubernetes

Ce qu'on produit en tant que dev c'est un artefact, le runtime c'est ce qui va permettre de faire tourner l'art
Le problème est que souvent c'est les équipe ops qui mettent en place le runtime alors que c'est les devs qui l'utilisent.
Donc dans l'idée un truc cool serait que les dev gèrent le runtime et c'est ça que permets docker. Le dev gère son environnement technique grâce à des container. 
L'artefact a changé. C'est maintenant une image docker comprenant le code source+ le containers ce qui permets lidem potence.

Quelques limitations tout de même en terme de gestion.
On a besoin d'un chef d'orchestre pour gérer tout ça que docker compose permet pas de gérer.
Un docker compose sur un seul serveur ça passe. Plusisuer docker compose sur 1 serveur ca devient galère. Plusieurs sur plusieurs serveur ça devient impossible docker compose sert pas à ça.
L'orchestrator par défaut pour gérer tout ça maintenant c'est Kubernetes

==== Kubernetes

Ça rend facile le management d'application (photo) 

Point archi:d'un côté les worker nodes qui font tourner les container de l'autre les master nodes qui font la gestion
Kube api via cette api on gère tout ! De Kubernetes.
**Dans Kubernetes TOUT est resources.**
On va d'écrire ces resources en yaml indiquant la resources vers cet état.
Et Kubernetes va faire en sorte de faire converger ces resources vers l'état qui nous intéresse


Resources de base de Kubernetes : le pod en gros un container
Replica set: Une consigne permettant de répliquer x fois une ressources
Le deployment : le container que je veux lancer, dans quelle version et quel état
Le deployment est donc la super ressource pour gérer les images successive de l'application. Il embarqué nos éléments précédents (Photos)

Configmap +secrets: injecter variables d'env +fichiers à nos pods
Differences config map en clair et secrets en chiffrés

Service :va nous permettre de Maintenant in veut publier l'applicatif. Le service permets de jouer les load balancer en interne.
Si on veut publier sur internet on va plutôt utiliser **l'ingress** c'est un reverse proxy.
Contrairement aux autre ressources l'ingress marche pas comme par défaut.
Le **namespace** espace de nommage regroupant toutes les ressources lié à un projet.

==== Episode 1 déployer infra

===== EKS

Eks c'est le Kubernetes managé propose par AWS d'amazone
Particularité d'eks
AZ=avaibility zone= centre réseau entier pour aws

===== terraform

Solution d'automation de l'infra et de providing des resources cloud.

===== GitlabCicd

Solution de choix pour le déploiement

===== Architecture:

Un dossier sur gitlab. Repo Terraform qu'on ça déployer chez Aws

Code Terraform des fichiers en. Tf.
On va d'écrire sous forme de code notre infra
On va indiquer notre provider, où il est déployé.
Les ressources, déclaré en snake case et indiquer sur quel provider c'est envoyé.
Declaratiin de Var (photo)
On peut fournir un fichier contenant toutes les variablss
Ou on peu déclarer des variables d'env
Ou on peut tout déclarer en lignes de commandes

Comment connaître l'ip du PROVIDER? => Variables output.
Le fichier. Tfstate est un fichier de sortie donnant l'ensemble des informations de notre infra déployée.
Mais fichier três três verbeux Donc Il est plus simple de définir aussi des variables d e sortie pour flag les infos qui nous interesse

Les modules permettent de recouper tout ça.

==== cycle de vie.

Terraform init pour initialiser tout ça.
Le plan va resynchro notre app avec le Tfstate.
L'apply fait le déploiement et défait le tfstate
Le destroy permet de tout effacer

==== Ansible :plate-forme pour configurer et manager des plate-forme

Controle node pour manager Ansible et ses modules. 
Inventaire permet de lister les machines notamment. Mais on va a plus l'utiliser pour lister où doivent être deployé les éléments 

Un playbook est une procédure d'install technique c'est ce que l'on d'exploit. 
Et on le déploie sur l'inventaire 

Ansible utilise aussi des modules et on peut remarque que comme Terraform on peut déclarer l'état attendu. 

Comment se connecter à K8s ? 
Le kube-config
Terraform ça filer un tf.state,que Ansible va aller chopper pour faire sa config

Artifacthub, site permettant de récupérer vite des packages.
Prendre le soin de transformer les commandes en module pour faire du déclaratif plutôt que de l'impératif 


Terraform comme Ansible vont utiliser le Tf. State

Terraform est la pour gérer des ressources.
Dans Ansible par contre on a des notions de tasks ! 
Donc si je veux par exemple demander d'attendre 5mn qu'un service soit up, Terraform est pas. Vraiment fait pour ça. 

Ansible n'a par contre pas de notion de tf state donc pas de manière de vraiment aller stocker des états et sauvegarder nos vars à réutiliser 

Donc des besoins différents remplis par chaque outils. 



==== PGSL

Notre base de donnée on la veut persistence par contre. Contrairement aux pods que l'on kill et recree

Bdd production ready: (photo) 
On pourrait utiliser le rdd Amazon qui filé tout ça production ready mais ca coûte une blinde et est très lié à Amazon 
On va donc se le créer nous meme

Dans K8S on a ce qu'on appelle un **Operator** c'est une ressource permettant de créer de nouvelles ressources. 
Puisque la nouvelle ressource est custom il nous faut un Controller qui est le cerveau qui interprétera la nouvelles ressource. 
On va donc creee

BucketS3 permet de stocker des infos, on va donc y persister les infos de notre bdd

A retenir de K8S  (photos) 

==== episode 4 Mes environnement

On veut passer de 1 à 'environnements. Va falloir modifier pas mal de trucs. 

Côte Terraform. On va ajouter un front end et un backend en créant des clusters

Côté Ansible on va juste mettre à jour l' inventory 
Côté K8S modif des yaml-> on va utiliser un moteur de templating. 
On va utiliser helm qu'on utilisait plus tôt juste comme manager de ressources mais on peut aussi l'utiliser pour gérer le templating via le 
Vqriables

Pipeline gitlab.
On va créer un cluster tesch'ique qui sera transient aux autres enviromment les elmements du cluster technique seront communs aux autres
Rancher outils supplémentaire d'administration 
Creatikn d'un projet en admin





Monitoring Centralisé par l'outils

Argocd, chef de chantier. Va comparer l'état des spes d'app déployé avec l'attendu et remonte des alertes si desynchro
Faire cette conf en manuel ok c'est faisable mais si j'ai 90 appli on va pas faire ça. Fort heureusement  dans Kubernetes tous est ressources ! 
Les éléments proposé par Argo peuvent eux aussi être déclaré en ressources et scriptés


==== Questions

Le code est très lié au cloud provider Donc so on change de cloud provider faut recoder, les apis à appeler doivent être mis à jour aussi.

Comment gerer les secret dans k8s. Deux manières
Le silksecret :chiffrer les secrets avec une clé posée dans un repo git mais difficile de faire de la rotation 
GoSecret projet gérer par la communauté marche via un secret store



=== Kubernetes, dépassionné et pour les ultra débutants

.Speaker: Sébastien Blanc (Aiven) , Horacio González (cofondateur du @FinistDevs, et des @RdvSpeakers.), , Sun Tan (RedHat) 

==== Pourquoi k8S ?

Retour d'exp, 
pain point 1: déploiement Manuel =fut un temps Sun Tan devait build ses projets à la main puis faire un ticket aux equipe de prod pour qu'ils déploient manuellement.
Pain point 2: soucis de scaling
Pain point 3: debugger en prod parce que les envs de dev et de prod sont rarement Iso.


===== Containers

(photo) 

Deux gros outils pour gérer les containers Docker et Podman

Récupération d'une image docker, on la docker run
Docker ps permet le listing des docker
Docker exec [container Id] command pour la'cer une commande dans le container

Limitation chaque container est isolé et n'a pas idée de ce qui ce passe dans les autres

Le principe des container est bien plus vieux que docker mais docker la remis au goût du jour en le rendant plus pratique
D'après Sun l'un des avantages de docker a été de permettre une utilisation assez similaire à ce qui est fait de manière traditionnelle avec du java.
Système de container orienté developer. 
Un autre avantage l'utilisation du docker permet de livrer une image avec runtime donc plus de soucis de "ca marche sur mon pc" 
Mais super difficile côté sys admin parce qu'au lieu d'avoir une seule appli à gérer installer et réparer y a maintenant 15 containers solo qui parlent entre elles. 
Il se tape donc plein de petites taches pas forcément très compliqués mais sans grandes valeures ajoutées. Dans une telle situation ce sys admin aimerait bien un petit stagiaire pour se charger de tout le taf rébarbatif. 
Kubernetes est notre stagiaire virtuel, il a pour responsabilité de gérer toutes les tâches de surveillance et de maintenance. Et il nous appelle quand y a de gros soucis. 
Kubernetes n'est ni le premier orchestrator ni même le plus perf. 
Mais il set sur un sweet spot entre fonctionnalités et complexité. 

==== Qu'est ce que Kubernetes ? 

K8S est bati autour d'un apiServer. Tout tourne autour de lui et est très modulaire. 
(Photo) 

Etcd=la memoire du container, 
les control planes 

Sur Kubernetes on utilize pas directement des containers, mais plutôt des pods. 
Pourquoi rajouter un niveau de complexité supplémentaire au lieu de juste utiliser directement les cokntainers. 
Imaginons on a un container wordpad qui discute avec un cokntainers Mysql. Audit de secu in ta tape dessus parce que pas de chiffrement de la communication entre les deux container comment régler ? 
On se tape de la recherche de lib compatible entre les deux containers. C'est galère. 
Avantage du pod, puisque le pod est l'unité de base il t'es possible de rajouter dans le circuit un pod chargé uniquement de la secu

Desired state management 
On est en mode déclaratif, on utilise des **manifest**, du yaml parce que Kubernetes provient du python
L'utilisation du yaml a ses limitations, mais un côté pratique est qu'il est facilement lisible.
Sa raison d'être est de nous permettre de filer des instructions à notre stagiaire 
On peut être super haut niveau et juste dire à notre stagiaire "déploie moi  mes pods, tu les fous où tu veux, tu les fous comme tu veux, je veux juste qu 'ils soient déployés. 
Dans ce cas là Kubernetes va déterminer par lui même le meilleure moyen de faire ce qui est demandé. 
Mais on peut aussi être très précis dans les manifest, donner des limitation de nombre d epods de mémoire utiliser, etc... 
Donc assez flexible comme systeme

Deploiement: usine à pod
Service va associé un déploiements a un point d'entrée dans le cluster via les nodes ports. (node port:port unique dans le cluster permettant d'y accéder) 
Mais si t'as 25 services t'as 25 ports a retenir, super chiant. C'est la où on entre en jeu le Ingress qui va rationaliser tout ça et service de port d'entrée unique. 
Le Load balancer: récupère une adresse IP public pour mettre en ligne notre projet

==== namespace

S'amuser avec Kubectl pratique quand on commence avec Kubernetes pour comprendre. C'est ligne de commande qui nous permet de communiquer avec le kubeapi
La syntaxe est simple: Kubectl verbe objet. 

Le names pace Est un niveaux d'abstraction supplémentaire. Il nous permets d'assigner nos pods, services cluster etc.. A un env
Kubens petit outils permettant de changer facilement de namespace
Pas mal d'outils permettant de rendre l'expérience Kubernetes plus facile d'utilisation. On commence on au début avec Kubectl mais on fini vite par utiliser tout ces éléments qui facilitent la vie


Dans une bdd de type yaml on peut créer des objets de type speaker

On modifie une ressource, on transmet la commande au controller et celui ci l'applique

Autoscale, si on demande à un cluster plus de resources qu'il n'en a, notre stagiaire va automatiquement commander des ressources.

=== Health Probe

Si on fait une requête au pod avant qu'il soit démarré erreur => readiness probes, vérifie que le le pod est up, si il retourne pas de 200 on retente dans x seconde.


Liveness probe pour vérifier si le probe est toujours vivant

Si un pod marche pas faire un Kubectl describe

Les secrets dans Kubernetes sont stockée dans ETCD, ils sont juste encodés en base 64 donc pas ultra secrets
Il faut donc coupler ça avec une infrastructure externe comme des vault.

Il ne faut pas tenter de stocker des choses dans un pod ou un node, ce sont des structures transitant.
Si on doit vraiment stocker des données dans Kubernetes il faut créer un volume persistant. Mais chaque cloud provider utilise des trucs differents
Il faut que le persistant volume create puisse claim Un bout de disque dur quelques part

=== NIX 

nix langage immmutable, utilisant le package manager appelé nix
nix-repl permets d'ecrire du code

Unfichier nix n'a qu'un seul operateur. Si on veut faire plusieurs chose dans un fichier nix on va utiliser l'operateur let va nous permettre d edeclarer plus de choses:

[source,nix]
----
let
    a=1;
    b=1;
    f= import ./add.nix;
in 
f {a=a}

first-package.nix
let
   pkgs= import <nixpkgs> {};
in
    pkgs.stdenv.mkdirection{
        name="devoxx";
        src="./."
    }

catimg.nix
let
   pkgs= import <nixpkgs> {};
in
    pkgs.stdenv.mkdirection{
        name="catimg";
        native.BuildimpImput[pkgs.make];
        src=pkgs.fetchFromGitHub{
            rev = "#Sha de la derniere revision du repo sur git"
            repo= "catimg";

        }
    }

----

un shell nix peut etre pur ou impur. Un shell est pur si il n'y a rien d'importé 
pkgs= import <nixpkgs> {};
pour pouvoir import des packages  on peut soit déclarer pkgs."nom de l'import" soit juste faire un with pkgs;
puis entre crochet déclaré tous les pkgs qui nous interessent

pkgs c'est la release de packaging de la distribution nix ou linux presente sur la machine.
donc le contenu de pkgs va dépendre de l'install ou de la version d

$out es là ou le builder de nix va ecrire ses sorties

construire une derivation depuis github consiste juste à dire au programme nix quel repo aller chercher, de quel owner , en quel version et derriere tu peux juste l'appeler
tous les packages nix sont ecrientt de la meme maniere

N'importe qui recuperant ce nix shell utilisera la meme version de java, de python, etc...

=== Les secrets de spring

==== principe de base de spring => Inversion de contrôle
Couplage lâche par interface. Il s'agit de savoir à quel point une classe peut en connaître une autre.
Il faut limiter la dépendance car plus y a de dépendance moins c'est simple à modifier/tester

Spring ça faire les instanciation pour nous ainsi que le code tuyauterie

Quand on démarre un application context un Bean factory post processor va lire les definitions de beans et peut meme les modifier avant de les initialiser.
Selon la configuration de bean utilisé c'est différant beans definitions qui seront utilisés

L'interface resource de spring. Sans l'exemple donnée le code récupère des infos d'un feed RSS youtube. Il a juste à modifier 
Spring a géré le code pour toute la partie jmx

Demo 2 BeanFactory post processor on a modifié le filtre. 


Le BeanFactory post processor va itereesur les definition de bean pour les modifié après leur charge par spring. 
Durant la phase d'initialisation intervient le Bean post processor avec un @PobeforeInitialisation et un @afterprocessInitializarion qui nous permettront de travailler sur ces beans avant et/ou après la génération des bean

== JEUDI

Ia classique on donne des données à la machine et on la spécialise, on l'entraîne pour faire un truc
Ia generative on lui file juste des données et on lui dit vas cherche, trouve moi un truc
Ia generative est le moment où les choses ont changé, c'est une rupture, un changement non anticipé aux implication non connu 
Comme pour tout autre révolution on s'est pas dit je vais faire un truc moins bon que moi. 
De la même manière on concevant l'Ia on s'est dit qu'on ferai un truc meilleur que nous au moins sous un aspect. 

L'humain donne du sens à ce qu'il fait. L'Ia va pouvoir des relations entre des trucs dont elle ne saisi pas le sens
Par exemple un nouveau paradigme de traduction en voyant des relations qu'on avait jamais vu. 



Création vs Innovation 

Pour l'instant la machine ne peut que créer pas Innover
L'innovation est de créer de manières différentes, de faire de la nouveauté. Pour l'instant la machine y ai pas encore. 

Concept de promp
 Au début on se disait des années 60 moi en tant que dev je dis à la machine ce qu'elle doit faire et pour l'utilisateur finale c'est la machine qui lui dit comment elle doit être utilisé (si y a pas de bouton pour faire ça l'utilisateur peut rie faire) 
Avec le prompt on parle a la machine avec un langage humain dans un contexte donné , donc donc l'humain reprend la makn

Github copilot, on code un truc on donne un contexte à l'ia, le contexte serait notre code. 
On va interagir avec L'Ia, on lui demande un truc il va proposer une réponse on peut lui dire si on accepte ou non et à apprendre selon nos retour positifs ou négatifs. 
Le principe du prompt est que la machine va saisir l'intention de l'utilisateur et repondre selon ce qu'elle a compris de l'intention 

==== que va nous permettre l'Ia ? 

Rapidité d'écriture 
Diminuer le temps de réalisation d'un truc fonctionnel 
Maintenablité
Sécurisation 

L'Ia generative est en train de changer tous les metiers de type création
D'après les stats IDC de l'année dernière on ne code que 10% de notre code. On utilise des framework, des librairies, des apis etc... 
Donc l'Ia pourrait peut être simplement enlever encore quelque % pour nous permettre de rester concentrer sur le code qui a du sens 

=== comment choisir une bdd

==== les db's relationnelles.

Data stockées dans des tables, celles ci ont reste relatoions entre elles, des jointures (exs Pgsql, Oracle...)

==== les db's  dockments

Les donnees sont stockées sous forme de docs, format json (ex mongoDB)

==== les db search

Index+ documents, possibilités de fuzzy seach c'est a dire avoir une tolérance aux fautes. (ex elasticsearch) 

Beaucoup beaucoup trop de type de bdd comment choisir ? 

Quelques axes de decisions.

=== comprendre son besoin

==== les types de requêtes

===== requête par id

Requête par identifiant, l'id peut faire le lien entre les tables, impacter l'agencement de kos données etc... 
Ca rend plus difficile de chercher sur les champs secondaire (photo) 
L'ajout d'un index peut être pratique si les donnes bouges pas constamment 

====== requête de recherche et recherche par score

Photos

==== transactions

Deux éléments a pendre en compte 
Transactions acid
Niveau d'isolation 

Les bases de données relationnelles sont généralement reine 

==== les résultats 

Est ce que je vais retourner toute la bdd ? Le faire sur 50 pages ? 

==== insertion et modification 

Taile des donnés, fréquences

==== suppressions et expiration 

Expiration automatique et coût de suppressions important car RGPD
Dépend totalement de l' implémentation 

==== langage de requêtes et drivers

==== structure 

Struct fixe:on connaît la donnée on peut a valider facilement - > relatilnnel
Struct flexible on a pas la main sur ce qui nous seras envoyé-> key value
(photo) 

Sparsedate et column est optimisé pour gérer les valeures null

==== Contrainte d'intégrité 

==== contrainte de type


=== evolutivite

Si la donnes est vouée à changer plutôt taper sur du relationnelle. 

=== volume de données. 

Volume faible<1go, bdd in memory 
Volume colossal

Disponibilité de la bdd: si multiple bdd, l'utilisateur rente de se CO à une bdd elle crash et automatiquement il est redirigé vês une autre instance, c'est la dispo

La scalabilité c'est géré le nombre d'knsrance généré selon la quantité d'utilisateurs qui tente de se co

Partitionnement stratégie de réplication 

Standby replica 
Warm scale En ecrit 
Hot: scale en lecture et noeud secondaire sans forcément la donnes la plus à jour (eventual inconsistency) 

Partition: on écrit sur la partition primaire et l'info est répliqué dans les partitions secondaires


Mode de clustering :
Cassandra. Plein d'options
Écrire sur un nœud, infos répliqué sur certain noeud. Risque d'appeler sur un nœud pas à jour. 

Possibilité d'écrire sur tous les nœuds mais lire sur un seul, on va ainsi optimisé la lecture. 
Strat intermediário écrire et lire sur 'a majorité absolu des nœuds e

Gestion automatique de replica et cluster via les bdd managés mais risque de vendor lock

=== Maintenance and recovery

Faire des snapshot régulier afin de pouvoir faire des recovery si problème. Les strats dependent des bdd

Il faut supprimer les données dans les backup aussi ! Non seulement pour le. RGPD mais aussi parce qu'on voudrait pas restorer des données censé être supprimé 

Les db's relationnels(photos) 

Utiliser les bdd existantes
Généralistes vs spécifique. Pas mettre toute les données dans la même bdd mais l'adapter au besoin
Tester régulièrement les perfis 

=== Journal de devoloppeur
A quel besoin répond le journal que je commence ?
Suivre ma carrière, capitaliser mes connaissances ?
C'est quoi un journal ? Une date + une trace

Traces informatives: infos sur le projets, les technos, les collègues, les succès ou difficultés.
Utiliser des indicateurs smart

Traces techniques :
choisir une techno dire tous les points positifs et négatifs (place d'expert)
Tracer les bugs, les choix d'implem pour retrouver pourquoi j'ai implementer un truc comme ça 6mois plus tard.

Sécurité, ne pas laisser traîner les notes que ce soit pour la secu projet ou même juste pour pas filé des infos persos à tous ceux qui passent
Fine tuning revenir régulièrement sur les précédentes entry à 1jour 1semaine et 1mois afin de savoir ce qu'k' peut améliorer dans notre capitalisation

=== l'histoire de la conteneurisation 

Conteur : pas de Def officiel, ensemble d'élément isolé du système 
Runtime :ensemble des logiciel permettant de faire tourner une application indepemment de l'os

L'idée originale de conteneur apparaît avec la création des système Unix (1972) ordinateur rare et cher donc partager les resources est essentiel.
De plus vu que peu de machines test et prod tournent en parallèle sur la même machine. Donc nécessité d'isoler les process= conteneur


Chroot notion de jail tu plage la src a un point que tu veux de l'arbo et on a pas acces au reste (d'où jail)

JULIA EVANS explication conteneur 

2004 Solaris. Zone Solaris fonctionnnt comme autant de serveur individuels.

2013/02 ajout des user namespace au noyaux Linux. C'est ce qui a rendu docker possible et qui arrive le mois suivant en mars. 
Objectif de docker rendre la gestion des containers simples pour les devs plutôt que centré ops. 

Pourquoi docker? Condtat il est plus simple de ship du café a travers le monde que de se partager des logiciels de manière fiable et automatique
1956 conteneur maritime pourquoi ? Quelque soit le contenu du contenuur voiture vélo pia'on le conteneur lui même a toujours le même dimensions, les même system d'ouvertures etc... Bref normalisation
C'est exactement ce qu'on va reprendre comme principe. 

C'est génial mais crainte et hésitation côté sécurité 
Le docker dame on fait tout et il a les droit root. Exploit facile pour être en root sur l'os du host.
Desilusion.
Puisque le problème viens du daemon monolithique les solutions proposé maintenant se font sans dameon comme Podman
Podman est daemonless et rootless

Webasembly(WASM) dans l'idée faire tourner autre chose que du Javascript

Grosse nouveauté Docker va intégrer wasm


=== Du bonheur dans le craft
Tout comme les artisans en tant que dev on a plein plein d'outils à notre disposition pour répondre à des besoins différents
Au delà des outils il peut aussi y avoir des soucis de méthode, de communication, de prise en compte des besoins non fonctionnel, du contexte.

Donc 3aspects à prendre en compte:
Outillage, le bkn outils pour le bon besoin 
Architecture, les bonnes techniques et partterrn 
Nature, la prise en compte de l'écosystème 


Outillage: bootstrap (angular, vue, spring..), environnements (ide), solution(pgsql tomcat..) hosting (opensjift, azure AWS..)

Architecture :découplage (hexahonal, clean archi..)
Pattern strategique (business domain, bounded context...)
Paterne tactique (rich domain...)
Vocabulair

Nature 

Quand en artisanat on a besoin de faire une table in appelle pas un expert cscien' ' circulaire, on cherche un un menuisier et on part du principe qu'il maîtrise un peu tojt

Alors pourquoi en tant que dev in se présente comme expert angular, ou un expert

Architecture hexagolnal


Bouncle de TDD, 
-Création du test rouge 
Correction en test vert
-notion de refeacto

3 aspects dans le live : pyramide de test+TDD+archi hexa


=== Architecture as code

The code is the truth but not the whole truth

==== A quelles questions répondre?

Qui? quoi ? quand? où ? Pourquoi ? Comment?
Y a un certain  nombre de question pour lesquelles on a pas de réponse. Souvent c'est "Pourquoi?" pourquoi est ce qu'on a décidé de developer det elle ou telle maniere. Il s'agit souvent là de question d'architecture

==== Mais comment documenter l'architecture ?
Exercice Cas d'usage Sup la seine.
Des casiers à paddle permettant de se deplacer 4

C4 methode pour faire de bon diagrammes.

 * C4 - Context:
    Liste des utilisateurs 

* C4 container:

Les elements signifiant de l'archi, ce ne sont pas forcément des container docker. Ce ne sont pas forcement  des modulesMaven.

* C4 
https://c4model.com/

COmment faire mieux?

STRUCTURIZR

https://structurizr.com/share/76352/documentation#start-structurizr-lite
https://dev.to/simonbrown/getting-started-with-structurizr-lite-27d0
On conttruit un modele plutot qu'une simple image et on peut l'associer à du code

Quand on commence à faire le diag d'archi on ne met pas la techno, quand l'archi est un peu plus sec on 
Attention le dsl est interpreté dans l'ordre
workspace.dsl
[source,dsl]
----
workspace{
    model{
        Super = person "SUPer" "un amateur de SUP voulant se promener sur la scene"
        renter = person "Loeur" "un loeur de paddle"
        supLocker = container
        
        enterprise{
        }
        view {
            #Vu system
            SystemContext supSystem supCintextVieuw{
                incluse * #va récuperer tous les élément de type Systeme 
                autoLayout
                }
            #Vu conteneur
            container supSystem supContainersVieuw{
                include *
                autoLayout
               }
               
           theme default
           styles{
            element "mobile {
                shape MobileDevicePortrait
           }
           
           prod = deployementEnvironment "Prod" {
                deploymentNode "Systemee de paiement prod"{
                    softwareSystemInstance paymentSystem
                }
                
           }    
----         
           La partie deploiement n'est pas présente dans C4, C' etait un peu trop abstrait mais finalement ça a été ajouté.
           pour gerer le deploiement faut creeer un env de deploiement ("deployementEnvironment") avec autant d'elements deploymentNode
           
          C'est important le theme et le style lorsqu'on présente le graph à des nons devs. Une façon un peu nice de reprensenter un objet interlligent 
          
          On créé un noeud messagingAsService et un noeud d'infrastructure
          Pas ouf mais il faut recreer les relation de messaging à chaque fois plutot que 'd'utiliser les relations crées par dfaut.
          
          
          plugin C4 dans vscode
    utilisation de la methode lintmodele sur notre fichier dsl.
    il va balancer des erreur pour toutes les mauvaises pratiques sur le model créé
    
    Structurizercloud enorme faille de secu tu venvoies des infos critiques sur l'appli à 
    
    Avec structurizr le cycle de vie de votre diagram d'archi n'est pas le cycle de vie de votre code
    on peut ce faire une methode our convertir le dsl en fichier uml
    check https://github.com/structurizr/dsl
    
    check IcePanel
    
    Les diagramme c'est bon juste pour le court terme!!! Privilégié le modele quand on arrive à des trucs plus définitifs
    beaucoup de resources de Simon Brown - the lost art of SoftwareDesign

== VENDREDI

=== clean as you code

Aujourd'hui le code source est partout, c'est devenu le cœur des entreprises d'où l'importance qu'il soit propre.
Clean code c'est quoi?

D'abord de quel type de code on parle quand on parle de clean code?
Code principal, le code support, code tiers (librairies) code non conventionnel (jupiter book par exemple)

*Clean code taxinomy* en avant premiere, nouvelle philo sonar(photo) 

Un code clair adapté à un but:
Clair (pas mille et un if imbriqué)
Cohérent (code adapté aux bonnes pratiques)
Structuré

Le pouvoir du clean code
Minimise l'effort d'entretien, réduit les friction pour les développeurs, augmente la longévité du code, améliore la secu. 

Pourquoi tout le monde ne fait pas du clean du code? 
Tous les devs ne sont pas au même niveaux et les langages sont vivant ce qui est du clean code aujourd'hui ne le sera pas forcément demain. 
Ca prend du temps et personne n'a envie de se plonger dans un code d'il y a 10ans pour le mettre au propre surtout si il marche. 


==== L'approche clean code

 Option1: repartir de 9,faire une appli Iso mais propre. Pas conseillé !
Option 2 refactoring : est ce qu'on va vraiment faire un truc de meilleur qualité sans introduire de nouveau problème ? Pas recommandé non plus
Option 3 clean as you code basé sur le *nouveau code*! L'idée est d'arrêter d'introduire de nouvelles erreurs. On fait de la qualité au fil de l' eau. Corriger les problèmes à la source
Ça responsabilise le développeur et lui donne des tips et bonnes pratiques

==== implementer le clean code

Sonarlint pour avoir les explications des erreurs direct dans l'IDe, en plus avec sonarqube on a la quality gate qui nous assure que ce qu'on va push est propre.

On estime à 20 % la quantité de code reecrit chaque année.
Donc finalement écrire du code propre au fur et à mesure va tout naturellement nettoyé l'existant.

=== Logiciels espion

La quantité de données récupéree par le renseignement augmente de manière exponentielle dans le monde militaire. Ça va de manière exponentielle.
Il en va de même dans le monde du commerce, entre les signaux radio, infra rouge, optique ou de réseau sociaux c'est un tsunami qui arrive.
Y a juste pas le nombre de bras nécessaire pour traiter tout ça. L'Ia va être indispensable.

Où sont ranger les logiciels d'ia classiquement ?-> DATACENTER
Des infrastructures et des outils efficaces et testés sont à la main des data engineer classique.

Dans le cadre d'une mission défense et sécurité c'est pas faisable.
Ca peut être des environnements hostiles, ou coupé de tout et même d'internet ou sur un porte avions par exemples.


Donc liste de problèmes:
Pas accès aux données du client, pas d'accès au hardware, peu d'accès aux utilisateurs finaux, pas d'accès au modèle une fois celui ci déployé. 
