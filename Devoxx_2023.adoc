= Devoxx France 2023
:imagesdir: ./images
:toc:

== Mercredi

=== Une Architecture GitOps from scratch : Gitlab, Ansible, Terraform, Kubernetes et AWS

.Speakers : Loïc Ortola et Aurélien Moreau (@Takima)

Infra complete en GitOps:
C'est quoi une infra complete? archi 3 tier

Stack appli:front en angular, Api spring boot
Database pgsql 
Kubernetes 
Prometheus pour la surveillance 
Terraform Ansible. 
(photo) 

Point de départ :compte AWS, un domaine acheté chez Gandi

Crash course
==== infra as code
1. Provisioning d'infra (hardware) . Il me faut des serveurs pour pouvoir host mon infra (serveurs, réseau etc... Provisioning d'knfra->cloud provider permettende monter des serveur plus facilement 
2.Configuration management installatiln du socle technique qui va nous permettre de faire tourner mon appli. management
3orchestration d'application. Faire tourner les appli, gérer le cycle de vie de l'app, gestio'
L'infra as code c'est faire tout ça ensemble 

IaC c'est faire sous forme de code 

==== Gitops
L'iaC comme d'écrire précédemment te représente ton truc à un temps t
Mais faut le versionner.
Gitops c'est d'avoir une source de vérité Git, dans lequel je mets mon code d'infra que je vais pouvoir synchroniser à un instant t par rapport à ce qui est déployé

==== De docker à Kubernetes
Ce qu'on produit en tant que dev c'est un artefact, le runtime c'est ce qui va permettre de faire tourner l'art
Le problème est que souvent c'est les équipe ops qui mettent en place le runtime alors que c'est les devs qui l'utilisent.
Donc dans l'idée un truc cool serait que les dev gèrent le runtime et c'est ça que permets docker. Le dev gère son environnement technique grâce à des container. 
L'artefact a changé. C'est maintenant une image docker comprenant le code source+ le containers ce qui permets lidem potence.

Quelques limitations tout de même en terme de gestion.
On a besoin d'un chef d'orchestre pour gérer tout ça que docker compose permet pas de gérer.
Un docker compose sur un seul serveur ça passe. Plusisuer docker compose sur 1 serveur ca devient galère. Plusieurs sur plusieurs serveur ça devient impossible docker compose sert pas à ça.
L'orchestrator par défaut pour gérer tout ça maintenant c'est Kubernetes

==== Kubernetes
Ça rend facile le management d'application (photo) 

Point archi:d'un côté les worker nodes qui font tourner les container de l'autre les master nodes qui font la gestion
Kube api via cette api on gère tout ! De Kubernetes.
**Dans Kubernetes TOUT est resources.**
On va d'écrire ces resources en yaml indiquant la resources vers cet état.
Et Kubernetes va faire en sorte de faire converger ces resources vers l'état qui nous intéresse


Resources de base de Kubernetes : le pod en gros un container
Replica set: Une consigne permettant de répliquer x fois une ressources
Le deployment : le container que je veux lancer, dans quelle version et quel état
Le deployment est donc la super ressource pour gérer les images successive de l'application. Il embarqué nos éléments précédents (Photos)

Configmap +secrets: injecter variables d'env +fichiers à nos pods
Differences config map en clair et secrets en chiffrés

Service :va nous permettre de Maintenant in veut publier l'applicatif. Le service permets de jouer les load balancer en interne.
Si on veut publier sur internet on va plutôt utiliser **l'ingress** c'est un reverse proxy.
Contrairement aux autre ressources l'ingress marche pas comme par défaut.
Le **namespace** espace de nommage regroupant toutes les ressources lié à un projet.

=== Episode 1 déployer infra
==== EKS
Eks c'est le Kubernetes managé propose par AWS d'amazone
Particularité d'eks
AZ=avaibility zone= centre réseau entier pour aws
==== terraform

Solution d'automation de l'infra et de providing des resources cloud.

==== GitlabCicd
Solution de choix pour le déploiement

==== Architecture:
Un dossier sur gitlab. Repo Terraform qu'on ça déployer chez Aws

Code Terraform des fichiers en. Tf.
On va d'écrire sous forme de code notre infra
On va indiquer notre provider, où il est déployé.
Les ressources, déclaré en snake case et indiquer sur quel provider c'est envoyé.
Declaratiin de Var (photo)
On peut fournir un fichier contenant toutes les variablss
Ou on peu déclarer des variables d'env
Ou on peut tout déclarer en lignes de commandes

Comment connaître l'ip du PROVIDER? => Variables output.
Le fichier. Tfstate est un fichier de sortie donnant l'ensemble des informations de notre infra déployée.
Mais fichier três três verbeux Donc Il est plus simple de définir aussi des variables d e sortie pour flag les infos qui nous interesse

Les modules permettent de recouper tout ça.

=== cycle de vie.
Terraform init pour initialiser tout ça.
Le plan va resynchro notre app avec le Tfstate.
L'apply fait le déploiement et défait le tfstate
Le destroy permet de tout effacer

=== Ansible :plate-forme pour configurer et manager des plate-forme
Controle node pour manager Ansible et ses modules. 
Inventaire permet de lister les machines notamment. Mais on va a plus l'utiliser pour lister où doivent être deployé les éléments 

Un playbook est une procédure d'install technique c'est ce que l'on d'exploit. 
Et on le déploie sur l'inventaire 

Ansible utilise aussi des modules et on peut remarque que comme Terraform on peut déclarer l'état attendu. 

Comment se connecter à K8s ? 
Le kube-config
Terraform ça filer un tf.state,que Ansible va aller chopper pour faire sa config

Artifacthub, site permettant de récupérer vite des packages.
Prendre le soin de transformer les commandes en module pour faire du déclaratif plutôt que de l'impératif 


Terraform comme Ansible vont utiliser le Tf. State

Terraform est la pour gérer des ressources.
Dans Ansible par contre on a des notions de tasks ! 
Donc si je veux par exemple demander d'attendre 5mn qu'un service soit up, Terraform est pas. Vraiment fait pour ça. 

Ansible n'a par contre pas de notion de tf state donc pas de manière de vraiment aller stocker des états et sauvegarder nos vars à réutiliser 

Donc des besoins différents remplis par chaque outils. 



===PGSL

Notre base de donnée on la veut persistence par contre. Contrairement aux pods que l'on kill et recree

Bdd production ready: (photo) 
On pourrait utiliser le rdd Amazon qui filé tout ça production ready mais ca coûte une blinde et est très lié à Amazon 
On va donc se le créer nous meme

Dans K8S on a ce qu'on appelle un **Operator** c'est une ressource permettant de créer de nouvelles ressources. 
Puisque la nouvelle ressource est custom il nous faut un Controller qui est le cerveau qui interprétera la nouvelles ressource. 
On va donc creee

BucketS3 permet de stocker des infos, on va donc y persister les infos de notre bdd

A retenir de K8S  (photos) 

=== episode 4 Mes environnement

On veut passer de 1 à 'environnements. Va falloir modifier pas mal de trucs. 

Côte Terraform. On va ajouter un front end et un backend en créant des clusters

Côté Ansible on va juste mettre à jour l' inventory 
Côté K8S modif des yaml-> on va utiliser un moteur de templating. 
On va utiliser helm qu'on utilisait plus tôt juste comme manager de ressources mais on peut aussi l'utiliser pour gérer le templating via le 
Vqriables

Pipeline gitlab.
On va créer un cluster tesch'ique qui sera transient aux autres enviromment les elmements du cluster technique seront communs aux autres
Rancher outils supplémentaire d'administration 
Creatikn d'un projet en admin





Monitoring Centralisé par l'outils

Argocd, chef de chantier. Va comparer l'état des spes d'app déployé avec l'attendu et remonte des alertes si desynchro
Faire cette conf en manuel ok c'est faisable mais si j'ai 90 appli on va pas faire ça. Fort heureusement  dans Kubernetes tous est ressources ! 
Les éléments proposé par Argo peuvent eux aussi être déclaré en ressources et scriptés


====Questions

Le code est très lié au cloud provider Donc so on change de cloud provider faut recoder, les apis à appeler doivent être mis à jour aussi.

Comment gerer les secret dans k8s. Deux manières
Le silksecret :chiffrer les secrets avec une clé posée dans un repo git mais difficile de faire de la rotation 
GoSecret projet gérer par la communauté marche via un secret store



=== Kubernetes, dépassionné et pour les ultra débutants

.Speaker: Sébastien Blanc (Aiven) , Horacio González (cofondateur du @FinistDevs, et des @RdvSpeakers.), , Sun Tan (RedHat) 

==== Pourquoi k8S ?
Retour d'exp, 
pain point 1: déploiement Manuel =fut un temps Sun Tan devait build ses projets à la main puis faire un ticket aux equipe de prod pour qu'ils déploient manuellement.
Pain point 2: soucis de scaling
Pain point 3: debugger en prod parce que les envs de dev et de prod sont rarement Iso.


===== Containers
(photo) 

Deux gros outils pour gérer les containers Docker et Podman

Récupération d'une image docker, on la docker run
Docker ps permet le listing des docker
Docker exec [container Id] command pour la'cer une commande dans le container

Limitation chaque container est isolé et n'a pas idée de ce qui ce passe dans les autres

Le principe des container est bien plus vieux que docker mais docker la remis au goût du jour en le rendant plus pratique
D'après Sun l'un des avantages de docker a été de permettre une utilisation assez similaire à ce qui est fait de manière traditionnelle avec du java.
Système de container orienté developer. 
Un autre avantage l'utilisation du docker permet de livrer une image avec runtime donc plus de soucis de "ca marche sur mon pc" 
Mais super difficile côté sys admin parce qu'au lieu d'avoir une seule appli à gérer installer et réparer y a maintenant 15 containers solo qui parlent entre elles. 
Il se tape donc plein de petites taches pas forcément très compliqués mais sans grandes valeures ajoutées. Dans une telle situation ce sys admin aimerait bien un petit stagiaire pour se charger de tout le taf rébarbatif. 
Kubernetes est notre stagiaire virtuel, il a pour responsabilité de gérer toutes les tâches de surveillance et de maintenance. Et il nous appelle quand y a de gros soucis. 
Kubernetes n'est ni le premier orchestrator ni même le plus perf. 
Mais il set sur un sweet spot entre fonctionnalités et complexité. 

==== Qu'est ce que Kubernetes ? 

K8S est bati autour d'un apiServer. Tout tourne autour de lui et est très modulaire. 
(Photo) 

Etcd=la memoire du container, 
les control planes 

Sur Kubernetes on utilize pas directement des containers, mais plutôt des pods. 
Pourquoi rajouter un niveau de complexité supplémentaire au lieu de juste utiliser directement les cokntainers. 
Imaginons on a un container wordpad qui discute avec un cokntainers Mysql. Audit de secu in ta tape dessus parce que pas de chiffrement de la communication entre les deux container comment régler ? 
On se tape de la recherche de lib compatible entre les deux containers. C'est galère. 
Avantage du pod, puisque le pod est l'unité de base il t'es possible de rajouter dans le circuit un pod chargé uniquement de la secu

Desired state management 
On est en mode déclaratif, on utilise des **manifest**, du yaml parce que Kubernetes provient du python
L'utilisation du yaml a ses limitations, mais un côté pratique est qu'il est facilement lisible.
Sa raison d'être est de nous permettre de filer des instructions à notre stagiaire 
On peut être super haut niveau et juste dire à notre stagiaire "déploie moi  mes pods, tu les fous où tu veux, tu les fous comme tu veux, je veux juste qu 'ils soient déployés. 
Dans ce cas là Kubernetes va déterminer par lui même le meilleure moyen de faire ce qui est demandé. 
Mais on peut aussi être très précis dans les manifest, donner des limitation de nombre d epods de mémoire utiliser, etc... 
Donc assez flexible comme systeme

Deploiement: usine à pod
Service va associé un déploiements a un point d'entrée dans le cluster via les nodes ports. (node port:port unique dans le cluster permettant d'y accéder) 
Mais si t'as 25 services t'as 25 ports a retenir, super chiant. C'est la où on entre en jeu le Ingress qui va rationaliser tout ça et service de port d'entrée unique. 
Le Load balancer: récupère une adresse IP public pour mettre en ligne notre projet

==== namespace
S'amuser avec Kubectl pratique quand on commence avec Kubernetes pour comprendre. C'est ligne de commande qui nous permet de communiquer avec le kubeapi
La syntaxe est simple: Kubectl verbe objet. 

Le names pace Est un niveaux d'abstraction supplémentaire. Il nous permets d'assigner nos pods, services cluster etc.. A un env
Kubens petit outils permettant de changer facilement de namespace
Pas mal d'outils permettant de rendre l'expérience Kubernetes plus facile d'utilisation. On commence on au début avec Kubectl mais on fini vite par utiliser tout ces éléments qui facilitent la vie
